fit$link, fit$family, nthreads, tol, keep, maxsize,
metric)
}
}else if(type == "branch and bound"){
if(parallel == "test-level"){
df <- BranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize, metric)
}else{
df <- BranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize, metric)
}
}else if(type == "ordered branch and bound"){
if(parallel == "test-level"){
df <- OrderBranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize,
metric, showprogress)
}else{
df <- OrderBranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize,
metric, showprogress)
}
}else if(type == "jumped branch and bound"){
if(parallel == "test-level"){
df <- JumpedBranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize, metric)
}else{
df <- JumpedBranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize, metric)
}
}else if(type == "reordered branch and bound"){
if(parallel == "test-level"){
df <- ParReorderBranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize,
metric, showprogress)
}else{
df <- ReorderBranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize,
metric, showprogress)
}
}else if(type == "reordered branch and bound2"){
if(parallel == "test-level"){
df <- ParReorderBranchAndBoundCpp(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize,
metric, showprogress)
}else{
df <- ReorderBranchAndBoundCpp2(fit$x, fit$y, fit$offset, indices, counts, method, grads,
fit$link, fit$family, nthreads, tol, keep, maxsize,
metric, showprogress)
}
}else{
stop("type must be one of 'forward', 'backward', 'branch and bound',
'ordered branch and bound', or 'best subset'")
}
df$model[df$model == -1] <- 1
df$order <- df$order[df$order != -1]
if(intercept){
df$model <- df$model[-1]
}else{
df$order <- df$order + 1
}
tempnames <- paste0(fit$names[as.logical(df$model)],
collapse = "+")
if(nchar(tempnames) == 0 && intercept){
tempnames <- 1
}else if(nchar(tempnames) == 0){
stop("Final model included no variables or intercept")
}
df$fit$formula <- as.formula(paste0(fit$yname, " ~ ", tempnames))
if(!intercept){
df$fit$formula <- deparse1(df$fit$formula) |>
paste0(" - 1") |>
as.formula()
}
df$fit$x <- model.matrix(df$fit$formula, fit$data, fit$contrasts)
df$fit$y <- fit$y
row.names(df$fit$coefficients) <- colnames(df$fit$x)
df$fit$names <- attributes(terms(df$fit$formula, data = df$fit$x))$factors |>
colnames()
df$fit$yname <- fit$yname
df$fit$parallel <- (parallel != FALSE)
df$fit$missing <- fit$missing
df$fit$link <- fit$link
df$fit$contrasts <- fit$contrasts
df$fit$family <- fit$family
df$fit$method <- method
if(fit$family == "Binomial"){
df$fit$ylevel <- fit$ylevel
}
FinalList <- list("finalmodel" = structure(df$fit, class = "FastGLM"),
"variables" = df$model,
"numchecked" = df$numchecked,
"order" = fit$names[df$order],
"type" = type,
"keep" = keep1,
"metric" = metric,
"bestmetric" = df$bestmetric)
structure(FinalList, class = "FastGLMVS")
}
#' @title Print Method for FastGLMVS
#' @param fit A FastGLMVS model object.
#' @param coefdigits Number of digits to display for coefficients table.
#' @param digits Number of digits to display for information after table.
#' @export
print.FastGLMVS <- function(VS, coefdigits = 4, digits = 0){
fit <- VS$finalmodel
coefs <- fit$coefficients
spaces <- row.names(coefs) |>
nchar() |>
max()
spaces <- spaces + 1
if(any(coefs$p.values < 2e-16)){
rounder <- 4
}else if(any(coefs$p.values < 10^(-coefdigits))){
rounder <- nchar(coefdigits) + 2
}else{rounder <- coefdigits}
coefs$p.values <- ifelse(coefs$p.values < 2e-16, "<2e-16" ,
ifelse(coefs$p.values < 10^(-coefdigits),
paste0("<1e-", coefdigits),
format(round(coefs$p.values, digits = coefdigits),
nsmall = max(coefdigits, rounder))))
Rounded <- sapply(coefs[, -4], round, digits = coefdigits, simplify = F)  |>
sapply(format, nsmall = coefdigits, simplify = F)
Rounded$p.values <- coefs$p.values
MoreSpaces <- sapply(Rounded, nchar, simplify = F) |>
sapply(max)
MoreSpaces <- pmax(MoreSpaces, c(9, 3, 7, 7))
MoreSpaces[1:3] <- MoreSpaces[1:3] + 1
cat("Variable Selection Info:\n")
cat(paste0(rep("-", spaces + sum(MoreSpaces)), collapse = ""))
cat("\n")
cat(paste0("Variables were selected using ", VS$type, " selection with ", VS$metric, "\n"))
cat(paste0("The best value of ", VS$metric, " obtained was ",
round(VS$bestmetric, digits = digits), "\n"))
cat(paste0("Number of models fit: ", VS$numchecked))
cat("\n")
if(!is.null(VS$keep)){
cat("Variables that were kept in each model: ", paste0(VS$keep, collapse = ", "))
}
cat("\n")
if(length(VS$order) == 0){
if(VS$type == "forward"){
cat("No variables were added to the model")
}else if(VS$type == "backward"){
cat("No variables were removed from the model")
}
}else if(VS$type == "forward" ){
cat("Order the variables were added to the model:\n")
}else if(VS$type == "backward" ){
cat("Order the variables were removed from the model:\n")
}
cat("\n")
if(length(VS$order) > 0){
for(i in 1:length(VS$order)){
cat(paste0(i, "). ", VS$order[i], "\n"))
}
}
cat(paste0(rep("-", spaces + sum(MoreSpaces)), collapse = ""))
cat("\n")
cat(paste0("Final Model:\n"))
cat(paste0(rep("-", spaces + sum(MoreSpaces)), collapse = ""))
cat("\n")
print(fit, coefdigits = coefdigits, digits = digits)
invisible(VS)
}
### TODO: Implement LRT CI using secant method
### Notes
#---------------#
### Reordered branch and bound works so well because it finds a good solution
### pretty quickly, finds the model selected by forward selection first.
### Also works well because the upper models always contain the worst variables,
### so as the better predictors get removed the likelihood on the larger models
### get worse very quickly and thus the lower bounds get larger quickly.
### My implementation of reordered branch and bound uses wide branching.
library(MASS)
LogisticSimul <- function(n, d, Bprob = .5){
x <- mvrnorm(n, mu = rep(1, d), Sigma = diag(.5, nrow = d, ncol = d) +
matrix(.5, ncol = d, nrow = d))
beta <- rnorm(d + 1, mean = 0, sd = 5)
beta[sample(2:length(beta), floor((length(beta) - 1) * Bprob))] = 0
p <- 1/(1 + exp(-x %*% beta[-1] - beta[1]))
y <- rbinom(n, 1, p)
df <- cbind(y, x) |>
as.data.frame()
df
}
NormalSimul <- function(n, d, Bprob = .5){
x <- mvrnorm(n, mu = rep(1, d), Sigma = diag(.5, nrow = d, ncol = d) +
matrix(.5, ncol = d, nrow = d))
beta <- rnorm(d + 1, mean = 0, sd = 5)
beta[sample(2:length(beta), floor((length(beta) - 1) * Bprob))] = 0
y <- x %*% beta[-1] + beta[1] + rnorm(n)
df <- cbind(y, x) |>
as.data.frame()
df$y <- df$V1
df$V1 <- NULL
df
}
PoissonSimul <- function(n, d, Bprob = .5){
x <- mvrnorm(n, mu = rep(1, d), Sigma = diag(.5, nrow = d, ncol = d) +
matrix(.5, ncol = d, nrow = d))
beta <- rnorm(d + 1, mean = 0, sd = 1)
beta[sample(2:length(beta), floor((length(beta) - 1) * Bprob))] = 0
y <- rpois(n, exp(x %*% beta[-1] + beta[1]))
df <- cbind(y, x) |>
as.data.frame()
df
}
BinomialData <- NormalSimul(1000, 25, Bprob = 0.95)
BinomialData <- NormalSimul(1000, 25, Bprob = 0.95)
system.time(Fit <- FastGLM(y ~ . , data = BinomialData, method = "Fisher",
family = "Normal", link = "identity", grads = 5,
parallel = FALSE, tol = 1e-4))
system.time(Fit <- FastGLM(y ~ . , data = BinomialData, method = "Newton",
family = "Normal", link = "identity", grads = 5,
parallel = FALSE, tol = 1e-4))
Rcpp::sourceCpp("C:/Users/Jacob/RProjects/FastGLM1/src/FastGLMHelpers.cpp")
system.time(Fit <- FastGLM(y ~ . , data = BinomialData, method = "Newton",
family = "Normal", link = "identity", grads = 5,
parallel = FALSE, tol = 1e-4))
Fit
BinomialData <- LogisticSimul(1000, 25, Bprob = 0.95)
system.time(Fit <- FastGLM(y ~ . , data = BinomialData, method = "Newton",
family = "Binomial", link = "logit", grads = 5,
parallel = FALSE, tol = 1e-4))
VariableSelection(Fit, type = "ordered branch and bound", metric = "AIC")
Rcpp::sourceCpp("C:/Users/Jacob/RProjects/FastGLM1/src/VariableSelection.cpp")
VariableSelection(Fit, type = "ordered branch and bound", metric = "AIC")
library(BranchGLM)
BinomialData <- LogisticSimul(1000, 25, Bprob = 0.95)
VariableSelection(y ~ ., data = BinomialData, family = "binomial",method = "Fisher",
link = "logit", type = "branch and bound", metric = "AIC",
parallel = FALSE)
library(BranchGLM)
library(BranchGLM)
library(MASS)
LogisticSimul <- function(n, d, Bprob = .5){
x <- mvrnorm(n, mu = rep(1, d), Sigma = diag(.5, nrow = d, ncol = d) +
matrix(.5, ncol = d, nrow = d))
beta <- rnorm(d + 1, mean = 0, sd = 5)
beta[sample(2:length(beta), floor((length(beta) - 1) * Bprob))] = 0
p <- 1/(1 + exp(-x %*% beta[-1] - beta[1]))
y <- rbinom(n, 1, p)
df <- cbind(y, x) |>
as.data.frame()
df
}
NormalSimul <- function(n, d, Bprob = .5){
x <- mvrnorm(n, mu = rep(1, d), Sigma = diag(.5, nrow = d, ncol = d) +
matrix(.5, ncol = d, nrow = d))
beta <- rnorm(d + 1, mean = 0, sd = 5)
beta[sample(2:length(beta), floor((length(beta) - 1) * Bprob))] = 0
y <- x %*% beta[-1] + beta[1] + rnorm(n)
df <- cbind(y, x) |>
as.data.frame()
df$y <- df$V1
df$V1 <- NULL
df
}
PoissonSimul <- function(n, d, Bprob = .5){
x <- mvrnorm(n, mu = rep(1, d), Sigma = diag(.5, nrow = d, ncol = d) +
matrix(.5, ncol = d, nrow = d))
beta <- rnorm(d + 1, mean = 0, sd = 1)
beta[sample(2:length(beta), floor((length(beta) - 1) * Bprob))] = 0
y <- rpois(n, exp(x %*% beta[-1] + beta[1]))
df <- cbind(y, x) |>
as.data.frame()
df
}
BinomialData <- LogisticSimul(1000, 25, Bprob = 0.95)
system.time(Fit <- BranchGLM(y ~ . , data = BinomialData, method = "Fisher",
family = "binomial", link = "logit", grads = 5,
parallel = FALSE, tol = 1e-4))
VariableSelection(y ~ ., data = BinomialData, family = "binomial",method = "Fisher",
link = "logit", type = "branch and bound", metric = "AIC",
parallel = FALSE)
VariableSelection(y ~ ., data = BinomialData, family = "binomial",method = "Fisher",
link = "logit", type = "branch and bound", metric = "AIC",
parallel = TRUE)
BinomialData <- LogisticSimul(1000, 25, Bprob = 0.5)
system.time(Fit <- BranchGLM(y ~ . , data = BinomialData, method = "Fisher",
family = "binomial", link = "logit", grads = 5,
parallel = FALSE, tol = 1e-4))
BinomialData <- LogisticSimul(1000, 25, Bprob = 0.5)
system.time(Fit <- BranchGLM(y ~ . , data = BinomialData, method = "Fisher",
family = "binomial", link = "logit", grads = 5,
parallel = FALSE, tol = 1e-4))
VariableSelection(y ~ ., data = BinomialData, family = "binomial",method = "Fisher",
link = "logit", type = "branch and bound", metric = "AIC",
parallel = TRUE)
VariableSelection(y ~ ., data = BinomialData, family = "binomial",method = "Fisher",
link = "logit", type = "branch and bound", metric = "AIC",
parallel = FALSE)
Cancer <- read.csv("wdbc.data", header = FALSE)[,-1]
usethis::use_vignette("BranchGLM-Vignette")
?MachineShop
library(MachineShop)
?MachineShop
mtcars
library(BranchGLM)
library(BranchGLM)
cars <- mtcars
cars <- mtcars
BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
carsFit <- BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
?BranchGLM
VariableSelection(carsFit, type = "forward")
VariableSelection(carsFit, type = "branch and bound")
VariableSelection(carsFit, type = "branch and bound", showprogress = FALSE)
### Forward selection with mtcars
VariableSelection(carsFit, type = "forward")
### Forward selection with mtcars
VariableSelection(carsFit, type = "backward")
VariableSelection(mpg ~. ,data = cars, family = "gaussian", link = "identity",
type = "branch and bound", showprogress = FALSE)
iris
data("Melanoma", package = "MASS")
Melanoma
iris$Species <- ifelse(iris$Species == "virginica", 1, 0)
flowersFit <- BranchGLM(Species ~ ., data = flowers, family = "binomial",
link = "logit")
flowers <- iris
flowers$Species <- ifelse(flowers$Species == "virginica", 1, 0)
flowersFit <- BranchGLM(Species ~ ., data = flowers, family = "binomial",
link = "logit")
flowersFit
flowers <- iris
flowers$Species <- ifelse(flowers$Species == "setosa", 1, 0)
flowersFit <- BranchGLM(Species ~ ., data = flowers, family = "binomial",
link = "logit")
flowersFit
Table(flowersFit)
flowers <- iris
flowers$Species <- ifelse(flowers$Species == "Setosa", 1, 0)
flowersFit <- BranchGLM(Species ~ ., data = flowers, family = "binomial",
link = "logit")
Table(flowersFit)
flowers <- iris
flowers$Species
flowers <- iris
flowers
flowers$Species
iris
data(iris)
iris
flowers <- data(iris)
flowers$Species <- ifelse(flowers$Species == "setosa", 1, 0)
flowers
flowers <- iris
flowers
flowers$Species <- ifelse(flowers$Species == "setosa", 1, 0)
flowersFit <- BranchGLM(Species ~ ., data = flowers, family = "binomial",
link = "logit")
Table(flowersFit)
mtcars
mtcars
flowersFit <- BranchGLM(am ~ ., data = cars, family = "binomial",
link = "logit")
Table(flowersFit)
flowersFit
?glmnet
library(glmnet)
?glmnet
?Cindex
?BranchGLM
predict(cars)
predict(carsFit)
carsFit$coefficients
?glmnet
coef(carsFit)
predict(carsFit)
carsFit$coefficients
?printCoefmat
library(BranchGLM)
### Using mtcars
library(BranchGLM)
cars <- mtcars
### Fitting linear regression model to predict mpg
carsFit <- BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
library(BranchGLM)
### Using mtcars
library(BranchGLM)
cars <- mtcars
### Fitting linear regression model to predict mpg
carsFit <- BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
library(BranchGLM)
### Using mtcars
library(BranchGLM)
cars <- mtcars
### Fitting linear regression model to predict mpg
carsFit <- BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
### Forward selection with mtcars
VariableSelection(carsFit, type = "forward")
### Backward elimination with mtcars
VariableSelection(carsFit, type = "backward")
### Forward selection with mtcars
VariableSelection(carsFit, type = "branch and bound", showprogress = FALSE)
### Can also use formula and data
VariableSelection(mpg ~. ,data = cars, family = "gaussian", link = "identity",
type = "branch and bound", showprogress = FALSE)
library(BranchGLM)
### Using mtcars
library(BranchGLM)
cars <- mtcars
### Fitting linear regression model to predict mpg
carsFit <- BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
### Forward selection with mtcars
VariableSelection(carsFit, type = "branch and bound", showprogress = FALSE)
### Can also use formula and data
VariableSelection(mpg ~. ,data = cars, family = "gaussian", link = "identity",
type = "branch and bound", showprogress = FALSE)
1L == 1
1.5 == as.integer(1.5)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# install.packages("BranchGLM")
### Using mtcars
library(BranchGLM)
cars <- mtcars
### Fitting linear regression model to predict mpg
carsFit <- BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
### Predict method
predict(carsFit)
### Accessing coefficients matrix
carsFit$coefficients
### Forward selection with mtcars
VariableSelection(carsFit, type = "forward")
### Backward elimination with mtcars
VariableSelection(carsFit, type = "backward")
VariableSelection(carsFit, type = "branch and bound", showprogress = FALSE)
### Can also use formula and data
FormulaVS <- VariableSelection(mpg ~ . ,data = cars, family = "gaussian",
link = "identity", type = "branch and bound",
showprogress = FALSE)
FormulaVS$order
FormulaVS$variables
FormulaVS$numchecked / 2^length(FormulaVS$variables)
VariableSelection(carsFit, type = "branch and bound", showprogress = FALSE)
FormulaVS <- VariableSelection(mpg ~ . ,data = cars, family = "gaussian",
link = "identity", type = "branch and bound",
keep = "hp",
showprogress = FALSE)
FormulaVS$numchecked / 2^length(FormulaVS$variables)
FormulaVS
FormulaVS$variables
FormulaVS
length(NULL)
FormulaVS$numchecked / 2^length(FormulaVS$variables)
FormulaVS$numchecked / 2^(length(FormulaVS$variables) - 1)
FormulaVS$numchecked
link = "identity", type = "branch and bound",
FormulaVS <- VariableSelection(mpg ~ . ,data = cars, family = "gaussian",
link = "identity", type = "branch and bound",
showprogress = FALSE)
### One way to judge how well the branch and bound performs is
FormulaVS$numchecked / 2^(length(FormulaVS$variables))
### Branch and bound with mtcars
VariableSelection(carsFit, type = "branch and bound", showprogress = FALSE)
### Can also use formula and data and can also specify keep
FormulaVS <- VariableSelection(mpg ~ . ,data = cars, family = "gaussian",
link = "identity", type = "branch and bound",
showprogress = FALSE)
### One way to judge how well the branch and bound performs is
FormulaVS$numchecked / 2^(length(FormulaVS$variables))
### Extracting final model
FormulaVS$finalmodel
### Example of using keep
VariableSelection(mpg ~ . ,data = cars, family = "gaussian",
link = "identity", type = "branch and bound",
keep = c("hp", "cyl"),
showprogress = FALSE)
VariableSelection(mpg ~ . ,data = cars, family = "gaussian",
link = "identity", type = "branch and bound",
keep = c("hp", "cyl"), metric = "BIC",
showprogress = FALSE)
?glm
?BranchGLM
library(BranchGLM)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
# install.packages("BranchGLM")
### Using mtcars
library(BranchGLM)
cars <- mtcars
### Fitting linear regression model to predict mpg
carsFit <- BranchGLM(mpg ~ ., data = cars, family = "gaussian", link = "identity")
carsFit
### Predict method
predict(carsFit)
### Accessing coefficients matrix
carsFit$coefficients
### Forward selection with mtcars
VariableSelection(carsFit, type = "forward")
### Backward elimination with mtcars
VariableSelection(carsFit, type = "backward")
VariableSelection(carsFit, type = "branch and bound", showprogress = FALSE)
FormulaVS <- VariableSelection(mpg ~ . ,data = cars, family = "gaussian",
link = "identity", type = "branch and bound",
showprogress = FALSE)
library(BranchGLM)
library(BranchGLM)
file.exists("~/.ssh/id_rsa.pub")
